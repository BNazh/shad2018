{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 2. Ранжирование (11 баллов)\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете так же должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поисковое ранжирование\n",
    "\n",
    "![](http://i.imgur.com/2QnD2nF.jpg)\n",
    "\n",
    "Задачу поискового ранжирования можно описать следующим образом: имеется множество документов $d \\in D$ и множество запросов $q \\in Q$. Требуется оценить *степень релевантности* документа по отношению к запросу: $(q, d) \\mapsto r$, относительно которой будет производиться ранжирование. Для восстановления этой зависимости используются методы машинного обучения. Обычно используется три типа:\n",
    " - признаки запроса $q$, например: мешок слов текста запроса, его длина, ...\n",
    " - документа $d$, например: значение PageRank, мешок слов, доменное имя, ...\n",
    " - пары $(q, d)$, например: число вхождений фразы из запроса $q$ в документе $d$, ...\n",
    "\n",
    "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
    "### Подходы к решению задачи ранжирования\n",
    "Существуют 3 основных подхода, различие между которыми в используемой функции потерь:\n",
    "  \n",
    "1. **Pointwise подход**. В этом случае рассматривается *один объект* (в случае поискового ранжирования - конкретный документ) и функция потерь считается только по нему. Любой стандартный классификатор или регрессор может решать pointwise задачу ранжирования, обучившись предсказывать значение таргета. Итоговое ранжирование получается после сортировки документов к одному запросу по предсказанию такой модели.\n",
    "2. **Pairwise подход**. В рамках данной модели функция потерь вычисляется по *паре объектов*. Другими словами, функция потерь штрафует модель, если отражированная этой моделью пара документов оказалась в неправильном порядке.\n",
    "3. **Listwise подход**. Этот подход использует все объекты для вычисления функции потерь, стараясь явно оптимизировать правильный порядок.\n",
    "\n",
    "### Оценка качества\n",
    "\n",
    "Для оценивания качества ранжирования найденных документов в поиске используются асессорские оценки. Само оценивание происходит на скрытых от обучения запросах $Queries$. Для этого традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
    "Для одного запроса DCG считается следующим образом:\n",
    "$$ DCG = \\sum_{i=1}^P\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
    "\n",
    "где $P$ — число документов в поисковой выдаче, $rel_i$ — релевантность (асессорская оценка) документа, находящегося на i-той позиции.\n",
    "\n",
    "*IDCG* — идеальное (наибольшее из возможных) значение *DCG*, может быть получено путем ранжирования документов по убыванию асессорских оценок.\n",
    "\n",
    "Итоговая формула для расчета *nDCG*:\n",
    "\n",
    "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
    "\n",
    "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
    "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
    "\n",
    "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите данные конкурса [Интернет-математика 2009](http://imat2009.yandex.ru/datasets). Там же находится описание данных. Разбейте обучающую выборку на обучение и контроль в соотношении 70 / 30. Обратите внимание на формат данных: разбивать необходимо множество запросов, а не строчки датасета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:53:06.193726Z",
     "start_time": "2018-10-10T18:53:06.190379Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:36:05.064576Z",
     "start_time": "2018-10-10T18:36:05.058639Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, GroupKFold, GroupShuffleSplit, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:33.276350Z",
     "start_time": "2018-10-10T18:59:27.431228Z"
    }
   },
   "outputs": [],
   "source": [
    "# read dataset, extract query ids\n",
    "X, y = datasets.load_svmlight_file('./imat2009-datasets/imat2009_learning.txt')\n",
    "with open('./imat2009-datasets/imat2009_learning.txt') as file:\n",
    "    query_ids = np.array([int(line.split('#')[1].strip()) for line in file.readlines()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:34.479412Z",
     "start_time": "2018-10-10T18:59:34.295487Z"
    }
   },
   "outputs": [],
   "source": [
    "relevant_queries = (pd.Series(y, index=query_ids).groupby(level=0).sum() > 0)\n",
    "relevant_queries = relevant_queries[relevant_queries].index\n",
    "query_mask = np.where([q in relevant_queries for q in query_ids])[0]\n",
    "X, y, query_ids = X[query_mask], y[query_mask], query_ids[query_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:36.979886Z",
     "start_time": "2018-10-10T18:59:36.953119Z"
    }
   },
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(1, test_size=0.3)\n",
    "\n",
    "train_ids, test_ids = next(gss.split(X, y, query_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:38.128718Z",
     "start_time": "2018-10-10T18:59:38.006140Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train = X[train_ids], y[train_ids]\n",
    "X_test, y_test = X[test_ids], y[test_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:38.462090Z",
     "start_time": "2018-10-10T18:59:38.450447Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((64483, 245), (27699, 245))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T13:57:49.618810Z",
     "start_time": "2018-10-10T13:57:49.615319Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Далее рассмотрим несколько подходов предсказания релевантности. Для оценивания качества моделей используйте метрику nDCG на контроле. В случае подбора гиперпараметров используйте кросс-валидацию по 5 блокам, где разбиение должно быть по запросам, а не строчкам датасета.\n",
    "\n",
    "**(1.3 балл) Задание 1.** *Pointwise* подход. Воспользовавшись известными вам техниками построения линейной регрессии, обучите модель, предсказывающую оценку асессора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:39.619971Z",
     "start_time": "2018-10-10T18:59:39.614471Z"
    }
   },
   "outputs": [],
   "source": [
    "import metrics as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:40.207321Z",
     "start_time": "2018-10-10T18:59:40.201240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:40.775325Z",
     "start_time": "2018-10-10T18:59:40.767501Z"
    }
   },
   "outputs": [],
   "source": [
    "def ndcg(y_true, y_pred, groups):\n",
    "    return np.nanmean([m.ndcg_score(np.array(y_true)[np.array(groups) == g], \n",
    "                                 np.array(y_pred)[np.array(groups) == g]) for g in set(groups)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T18:59:41.419133Z",
     "start_time": "2018-10-10T18:59:41.412488Z"
    }
   },
   "outputs": [],
   "source": [
    "def cv_test(regr):\n",
    "    cv_pred = cross_val_predict(regr, X_train, y_train, groups=query_ids[train_ids], cv=5)\n",
    "    cv_ndcg = ndcg(y_train, cv_pred, query_ids[train_ids])\n",
    "    regr.fit(X_train, y_train)\n",
    "    val_pred = regr.predict(X_test)\n",
    "    val_ndcg = ndcg(y_test, val_pred, query_ids[test_ids])\n",
    "    return dict(\n",
    "        cv_pred = cv_pred,\n",
    "        cv_ndcg = cv_ndcg,\n",
    "        val_pred = val_pred,\n",
    "        val_ndcg = val_ndcg,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:02:52.969574Z",
     "start_time": "2018-10-10T18:59:44.856495Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8417875026337917 0.8358849037424148\n"
     ]
    }
   ],
   "source": [
    "cv_res_lin = cv_test(LinearRegression())\n",
    "print(cv_res_lin['val_ndcg'], cv_res_lin['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ранжируем с XGBoost\n",
    "\n",
    "XGBoost имеет несколько функций потерь для решения задачи ранжирования:\n",
    "1. **reg:linear** — данную функцию потерь можно использовать для решения задачи ранжирование *pointwise* подходом.\n",
    "2. **rank:pairwise** — в качестве *pairwise* модели в XGBoost реализован [RankNet](http://icml.cc/2015/wp-content/uploads/2015/06/icml_ranking.pdf), в котором минимизируется гладкий функционал качества ранжирования: $$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = log(1 + e^{-M}), $$ где $ a(x) $ - функция ранжирования. Суммирование ведется по всем парам объектов, для которых определено отношение порядка, например, для пар документов, показанных по одному запросу. Таким образом функция потерь штрафует за то, что пара объектов неправильно упорядочена.\n",
    "3. **rank:map, rank:ndcg** — реализация [LambdaRank](https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/MSR-TR-2010-82.pdf) для двух метрик: [MAP](https://en.wikipedia.org/wiki/Information_retrieval#Mean_average_precision) и **nDCG**. Известно, что для того, чтобы оптимизировать негладкий функционал, такой как **nDCG**,  нужно домножить градиент функционала $ Obj(a) $ на значение $\\Delta NDCG_{ij} $ — изменение значения функционала качества при замене $x_i$ на $ x_j$.  Поскольку для вычисления метрик необходимы все объекты выборки, то эти две ранжирующие функции потерь являются представителями класса *listwise* моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2.7 балла) Задание 2.** Обучите модели **reg:linear**, **rank:pairwise** и **rank:ndcg**, в качестве метрики оценки качества (*eval_metric*) используя *nDCG*, а в качестве бустера решающее дерево. Настройте [параметры](https://github.com/dmlc/xgboost/blob/master/doc/parameter.md) алгоритма и добейтесь высокого качества на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:02:52.975235Z",
     "start_time": "2018-10-10T19:02:52.972448Z"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:10:33.641738Z",
     "start_time": "2018-10-10T19:06:17.638645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.853174921068299 0.8505660788941586\n"
     ]
    }
   ],
   "source": [
    "cv_res_reg_lin = cv_test(xgb.XGBRegressor(objective='reg:linear'))\n",
    "print(cv_res_reg_lin['val_ndcg'], cv_res_reg_lin['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:15:03.901234Z",
     "start_time": "2018-10-10T19:10:33.645898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8485820474612767 0.8441353403123042\n"
     ]
    }
   ],
   "source": [
    "cv_res_rank_pair = cv_test(xgb.XGBModel(objective='rank:pairwise', groups=query_ids[train_ids]))\n",
    "print(cv_res_rank_pair['val_ndcg'], cv_res_rank_pair['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:17:53.269032Z",
     "start_time": "2018-10-10T19:16:23.128128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541392592596167 0.7499498002147456\n"
     ]
    }
   ],
   "source": [
    "cv_res_rank_ndcg = cv_test(xgb.XGBModel(objective='rank:ndcg', groups=query_ids[train_ids]))\n",
    "print(cv_res_rank_ndcg['val_ndcg'], cv_res_rank_ndcg['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nDCG для rank:ndcg выглядит неплохо, однако алгоритм выдал по 0.5 всем документам..\n",
    "возможно, это как-то связано с [issue](https://github.com/dmlc/xgboost/issues/2768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:53:27.510941Z",
     "start_time": "2018-10-10T19:53:27.505579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ptp(cv_res_rank_ndcg['val_ndcg']), np.ptp(cv_res_rank_ndcg['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Пользовательская функция потерь\n",
    "\n",
    "Библиотека XGBoost позволяет использовать пользовательские функции потерь. Для этого необходимо реализовать функцию, принимающую на вход вектор предсказанных значений и обучающую выборку, и возвращающую градиент и гессиан, посчитанный по входным данным.\n",
    "\n",
    "Важно отметить, что XGBoost использует диагональную аппроксимацию гессиана, таким образом все недиагональные элементы считаются малозначимыми и приравниваются нулю, поэтому и градиент, и гессиан являются векторами длины размера обучающей выборки.\n",
    "\n",
    "**(5.7 балла) Задание 3.** Реализуйте экспоненциальную функцию потерь для XGBoost:\n",
    "$$ Obj = \\sum_{i \\prec j} \\mathcal{L}\\left(a(x_j) - a(x_i)\\right) \\rightarrow min $$ $$ \\mathcal{L}(M) = e^{-M} $$\n",
    "\n",
    "Обучите модель с помощью данной функции потерь, настройте параметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Комментарии к реализации**\n",
    "\n",
    "В случае ранжирования XGBoost'у необходимо знать о разбиении всех объектов на группы. В нашем случае в одну группу будут входить документы, соответствующие одному запросу. Функция, считающая градиент и гессиан по данным, должна знать данное разбиение датасета. Однако питоновский интерфейс класса *DMatrix* (в котором хранится датасет) не дает возможности получить это разбиение. В этом случае нужно реализовать функцию потерь в качестве функтора, конструктор которого принимает разбиение на группы в качестве параметра.\n",
    "\n",
    "Пример реализации своей функции потерь можно найти на соответствующем семинаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:17:53.277075Z",
     "start_time": "2018-10-10T19:17:53.271674Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExponentialPairwiseLoss(object):\n",
    "    def __init__(self, groups):\n",
    "        self.groups = np.array(groups)\n",
    "                            \n",
    "    def __call__(self, y_true, preds):\n",
    "        y_true = np.array(y_true)\n",
    "        preds = np.array(preds)\n",
    "#         print(preds.min(), preds.max())\n",
    "        \n",
    "        grad = np.zeros_like(y_true)\n",
    "        hess = np.zeros_like(y_true)\n",
    "        for group in set(self.groups):\n",
    "            group_indices = np.where(self.groups == group)[0]\n",
    "            for j in group_indices:\n",
    "                for i in group_indices:\n",
    "                    if y_true[i] < y_true[j]:\n",
    "#                         print(i, j, y_true[i] , y_true[j], preds[j] - preds[i])\n",
    "                        exp = np.exp(-(preds[j] - preds[i]))\n",
    "                        grad[i] += exp\n",
    "                        grad[j] += - exp\n",
    "                        hess[i] += exp\n",
    "                        hess[j] += exp\n",
    "        return grad, hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:17:53.295032Z",
     "start_time": "2018-10-10T19:17:53.279333Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "def cross_val_predict_with_obj(regr, obj, X_train, y_train, groups, cv_n=5):\n",
    "    kf = GroupKFold(cv_n)\n",
    "    cv_preds = np.zeros_like(y_train)\n",
    "    for tr_i, te_i in kf.split(X_train, y_train, groups):\n",
    "        regr = clone(regr).set_params(objective=obj(groups[tr_i]))\n",
    "        regr.fit(X_train[tr_i], y_train[tr_i])\n",
    "        cv_preds[te_i] = regr.predict(X_train[te_i])\n",
    "    return cv_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:37:40.607654Z",
     "start_time": "2018-10-10T19:37:40.591899Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_pred_exp = cross_val_predict_with_obj(xgb.XGBModel(), \n",
    "                                         ExponentialPairwiseLoss, X_train, y_train, query_ids[train_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:38:22.872251Z",
     "start_time": "2018-10-10T19:38:22.867114Z"
    }
   },
   "outputs": [],
   "source": [
    "regr = xgb.XGBModel(objective=ExponentialPairwiseLoss(groups=query_ids[train_ids]))\n",
    "regr.fit(X_train, y_train)\n",
    "pred_exp = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:38:32.740961Z",
     "start_time": "2018-10-10T19:38:31.118468Z"
    }
   },
   "outputs": [],
   "source": [
    "cv_res_rank_exp = dict(\n",
    "    cv_pred = cv_pred_exp,\n",
    "    cv_ndcg = ndcg(y_train, cv_pred_exp, query_ids[train_ids]),\n",
    "    val_pred = pred_exp,\n",
    "    val_ndcg = ndcg(y_test, pred_exp, query_ids[test_ids])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-10T19:38:33.851581Z",
     "start_time": "2018-10-10T19:38:33.848024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8495593036691309 0.8464663564304656\n"
     ]
    }
   ],
   "source": [
    "print(cv_res_rank_exp['val_ndcg'], cv_res_rank_exp['cv_ndcg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1.3 балл) Задание 4.** Сравните построенные модели с точки зрения метрики nDCG на контроле и проанализируйте полученные результаты:\n",
    "  - какая модель работает лучше всего для данной задачи? \n",
    "  - в чем достоинства/недостатки каждой? \n",
    "  - сравните модели между собой: \n",
    "   - получается ли сравнимое качество линейного pointwise подхода с остальными моделями? \n",
    "   - заметна ли разница в качестве при использовании бустинга с разными функциями потерь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше всего для задачи отработал xgboost pointwise подход. Особенной разницы в результатах не заметно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
